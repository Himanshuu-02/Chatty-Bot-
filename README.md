# ğŸ¤– ChattyBot â€“ AI Chatbot Backend

ChattyBot is a full-stack AI chatbot backend built using **FastAPI**, **MongoDB**, and **Ollama (Gemma model)**.  
It supports multi-conversation chat history, conversation-based deletion, and custom AI identity control.

Developed by **Engineer Himanshu**.

---

## ğŸš€ Features

- âœ… AI responses using Gemma model (via Ollama)
- âœ… Multi-conversation support
- âœ… Chat history per conversation
- âœ… Delete entire conversation
- âœ… MongoDB database integration
- âœ… Custom AI identity (does not expose base model)
- âœ… RESTful API design
- âœ… Ready for frontend integration
- âœ… Deployment-friendly structure (Base URL support)

---

## ğŸ›  Tech Stack

- **Backend Framework:** FastAPI
- **Database:** MongoDB
- **Database Driver:** Motor (Async MongoDB)
- **AI Model Runtime:** Ollama
- **Model Used:** llama3.2:1b
- **Server:** Uvicorn

---

## ğŸ“ Project Structure

```
project/
â”‚
â”œâ”€â”€ main.py              # Main FastAPI app
â”œâ”€â”€ database.py          # MongoDB connection
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the repository

```bash
git clone <your-repo-url>
cd client
```

---

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows
```

---

### 3ï¸âƒ£ Install Dependencies

If requirements file not created:

```bash
pip install fastapi uvicorn motor requests python-dotenv
```

---

### 4ï¸âƒ£ Install & Run Ollama

Download Ollama from:
https://ollama.com

Pull the model:

```bash
ollama pull llama3.2:1b
```

Start Ollama server:

```bash
ollama run llama3.2:1b
```

---

### 5ï¸âƒ£ Start FastAPI Server

```bash
uvicorn main:app --reload
```

Server will run at:

```
http://127.0.0.1:8000
```

Swagger Docs:

```
http://127.0.0.1:8000/docs
```

---

## ğŸ§  How It Works

### 1ï¸âƒ£ User sends message to:

```
POST /chat
```

Body:

```json
{
  "message": "Hello",
  "conversation_id": "123456"
}
```

---

### 2ï¸âƒ£ Backend:

- Sends prompt to Ollama
- Receives AI response
- Saves message + reply in MongoDB
- Returns response to frontend

---

### 3ï¸âƒ£ Chat History

```
GET /history?conversation_id=123456
```

Returns all messages for that conversation only.

---

### 4ï¸âƒ£ Delete Conversation

```
DELETE /delete_conversation/{conversation_id}
```

Deletes all messages inside that conversation.

---

## ğŸ—„ Database Structure (MongoDB)

Collection: `chat_collection`

Example document:

```json
{
  "_id": ObjectId,
  "conversation_id": "123456",
  "user_message": "Hello",
  "ai_reply": "Hi there!",
  "timestamp": "2025-02-26T10:00:00"
}
```

---

## ğŸ¯ AI Identity Control

System prompt ensures:

- Bot name: **ChattyBot**
- Created by: **Engineer Himanshu**
- Does NOT mention:
  - Google
  - DeepMind
  - Meta
  - Base model details

---

## ğŸŒ Frontend Integration

Use a Base URL:

```js
const BASE_URL = "http://127.0.0.1:8000";
```

Example API call:

```js
axios.post(`${BASE_URL}/chat`, {
  message: message,
  conversation_id: currentConversationId
});
```

---

## ğŸ§© Future Improvements

- User authentication (JWT)
- Streaming responses
- Conversation titles
- Pagination for history
- Deployment on AWS / Render / Railway
- Docker support

---

## ğŸ“¦ Deployment Ready

When deploying:

- Change BASE_URL
- Use MongoDB Atlas
- Use environment variables for secrets
- Run with production server (Gunicorn)

---

## ğŸ‘¨â€ğŸ’» Developer

Engineer Himanshu  
Software Developer  

---

## ğŸ“œ License

This project is open-source and free to use.

---

# â­ Final Notes

This project demonstrates:

- Backend API design
- AI integration
- Database architecture
- Multi-conversation handling
- Clean separation between frontend & backend

Perfect for portfolio and production-level learning.
